{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adlimberkey/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23722, 234972)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.externals import joblib\n",
    "import re\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import scipy.spatial.distance\n",
    "import numba \n",
    "from numba import jit\n",
    "\n",
    "\n",
    "nyt_unique=pd.read_csv('nyt_uniques_topicsLabeled.csv')\n",
    "reuters_unique = pickle.load( open( \"20180516-20180621_reuters_unique.pkl\", \"rb\" ) )\n",
    "reuters_titles_first_10000 = pickle.load( open( 'reuters_titles_first10000.pkl', \"rb\" ) )\n",
    "reuters_titles_rest = pickle.load( open( 'reuters_titles_rest.pkl', \"rb\" ) )\n",
    "\n",
    "def token_stem(text):\n",
    "    # tokenize by sentence and word. this way you ensure you get rid of punctuations\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    tokens_with_letters = []\n",
    "    # use the regex library to search only for items that contain letters. this will enable you to eliminate punctuation\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            tokens_with_letters.append(token)\n",
    "    stems = [stemmer.stem(t) for t in tokens_with_letters] #\"stems\" part\n",
    "    return stems\n",
    "\n",
    "def token(text): #difference between this one and the one above is the \"stems\" part\n",
    "    #same as above\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    tokens_with_letters = []\n",
    "    # same as above\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            tokens_with_letters.append(token)\n",
    "    return tokens_with_letters\n",
    "\n",
    "reuters_unique.reset_index(inplace=True)\n",
    "reuters_unique.drop('index',axis=1,inplace=True)\n",
    "reuters_titles_first_10000.extend(reuters_titles_rest)\n",
    "reuters_unique['titles']=pd.Series(reuters_titles_first_10000)\n",
    "\n",
    "nyt_labeled_only=nyt_unique.loc[nyt_unique['Section'] != 'Other']\n",
    "nyt_labeled_only.reset_index(inplace=True)\n",
    "nyt_labeled_only.drop('index',axis=1,inplace=True)\n",
    "\n",
    "nyt_titles=nyt_labeled_only['Title'].tolist()\n",
    "#now, keep in mind that we're adding reuters titles to nyt_titles, so we essentially have all the titles in a \n",
    "#variable called \"nyt_titles\". \n",
    "nyt_titles.extend(reuters_titles_first_10000)\n",
    "\n",
    "for n,i in enumerate(nyt_titles):\n",
    "    if type(i)!=str: \n",
    "        nyt_titles[n]=\"URL Error\"\n",
    "\n",
    "nyt_titles=list(map(lambda unicode_line:unicode_line.translate({ord(c): None for c in 'Äòôúîù'}),nyt_titles))\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stemmer = SnowballStemmer(\"english\") \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english',use_idf=True, norm='l2',tokenizer=token_stem, ngram_range=(1,3))\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(nyt_titles)\n",
    "\n",
    "nyt_titles_tfidf=tfidf_matrix[0:1400,:].toarray()\n",
    "reuters_titles_tfidf=tfidf_matrix[1400:,:].toarray()\n",
    "\n",
    "print(tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 22322)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#title_distances=scipy.spatial.distance.cdist(nyt_titles_tfidf,reuters_titles_tfidf,'cosine')\n",
    "#pf=open('title_distances.pkl','wb')\n",
    "#pickle.dump(title_distances,pf)\n",
    "title_distances = pickle.load( open( \"title_distances.pkl\", \"rb\" ) )\n",
    "title_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns=['NYT_Orig.Index','NYT_Date_Pub','NYT_Link','NYT_Keywords','NYT_Article','NYT_Title','NYT_Section',\n",
    "        'NYT_Date_Printed','NYT_Missing_Articles/Day','Reuters_Date','Reuters_Link','Reuters_Keywords','Reuters_Article',\n",
    "        'Reuters_Title','title_distance']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the repeat to title_distances.shape[1], nyt_x to nyt_labeled_only\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "nyt_df=pd.DataFrame(np.repeat(nyt_labeled_only.values,title_distances.shape[1],axis=0),columns=nyt_labeled_only.columns)\n",
    "reuters_df=pd.DataFrame(pd.np.tile(reuters_unique, (title_distances.shape[0], 1)),columns=reuters_unique.columns)\n",
    "title_dist_series=pd.Series(flatten(title_distances.tolist()))\n",
    "big_df=pd.concat([nyt_df, reuters_df], axis=1)\n",
    "big_df['title_distances']=pd.Series(flatten(title_distances.tolist()))\n",
    "big_df.columns=Columns\n",
    "pf=open('big_df.pkl','wb')\n",
    "pickle.dump(big_df,pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31250800, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23722"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyt_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.962692858949499"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_list=[]\n",
    "for i in nyt_titles:\n",
    "    length_list.append(len(i.split()))\n",
    "    \n",
    "sum(length_list)/len(length_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31250800, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

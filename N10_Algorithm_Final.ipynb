{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#Read the dataframe of all NYT/Reuters article pairs (around 30m rows)\n",
    "df = pickle.load( open( \"big_df.pkl\", \"rb\" ) )\n",
    "\n",
    "#Group by NYT_Link first. This way you can hash out the pairs that have smallest 10 distances\n",
    "#per NYT article\n",
    "gb=df.groupby(['NYT_Link'])\n",
    "\n",
    "#now, we will be taking the intersections of 10 smallest article, keyword, title distances \n",
    "#per NYT article\n",
    "sample={}\n",
    "for key,value in gb.groups.items():\n",
    "    sample[key]={\"all_3\":set(gb.get_group(key).article_distances.nsmallest(10)\n",
    "                    .index).intersection(set(gb.get_group(key).keyword_distances.nsmallest(10).\n",
    "                                             index),set(gb.get_group(key).title_distance.nsmallest(10).index))}\n",
    "\n",
    "#take only the pair for which there exists an element in the intersection of all article, keyword\n",
    "#title smallest 10 distances (paper explains this algorithm more concisely)\n",
    "check_lst=[]\n",
    "for key,value in sample.items():\n",
    "    if len(value['all_3'])>=1:\n",
    "        check_lst.append(list(value['all_3']))\n",
    "    \n",
    "\n",
    "#you end up with a list of lists. 'flatten' that to get a list \n",
    "flatten=lambda l:[item for sublist in l for item in sublist]\n",
    "check_lst=flatten(check_lst)\n",
    "\n",
    "#use the indices you have retrieved and pick out the corresponding elements from your big df\n",
    "close_articles_df1=df.iloc[check_lst].copy()\n",
    "#clean NYT articles. \n",
    "close_articles_df1['NYT_Article_Cleaned']=close_articles_df1.NYT_Article.apply(lambda unicode_line:unicode_line.translate({ord(c): None for c in 'Äòôúîù'}))\n",
    "#write the result to a csv \n",
    "close_articles_df1.to_csv('close_articles_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
